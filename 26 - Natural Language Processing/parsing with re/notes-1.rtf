{\rtf1\ansi\ansicpg1252\cocoartf2511
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fnil\fcharset0 HelveticaNeue;\f2\fnil\fcharset0 Monaco;
\f3\fnil\fcharset0 HelveticaNeue-Italic;\f4\froman\fcharset0 Times-Roman;}
{\colortbl;\red255\green255\blue255;\red56\green56\blue56;\red255\green255\blue255;\red17\green16\blue23;
\red229\green227\blue232;\red164\green191\blue255;\red23\green23\blue23;\red252\green115\blue96;\red129\green131\blue134;
\red254\green219\blue112;\red117\green255\blue242;}
{\*\expandedcolortbl;;\cssrgb\c28235\c28235\c28235;\cssrgb\c100000\c100000\c100000;\cssrgb\c8235\c7843\c12157;
\cssrgb\c91765\c91373\c92941;\cssrgb\c70196\c80000\c100000;\cssrgb\c11765\c11765\c11765;\cssrgb\c100000\c53725\c45098;\cssrgb\c57647\c58431\c59608;
\cssrgb\c100000\c87843\c51373;\cssrgb\c51373\c100000\c96078;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid1\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}}
\paperw11900\paperh16840\margl1440\margr1440\vieww28300\viewh17700\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs28 \cf0 \
\pard\pardeftab720\sl560\sa240\partightenfactor0

\f1\fs35\fsmilli17600 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 And there you go! Now you have the toolkit to dig into any piece of text data and perform natural language parsing with regular expressions. What insights will you gain, or what bias may you uncover? Let\'92s review what you have learned:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl560\sa120\partightenfactor0
\ls1\ilvl0\cf2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 The\'a0
\f2\fs21\fsmilli10800 \cf4 \cb5 \strokec4 re
\f1\fs35\fsmilli17600 \cf2 \cb3 \strokec2 \'a0module\'92s\'a0
\f2\fs21\fsmilli10800 \cf4 \cb5 \strokec4 .compile()
\f1\fs35\fsmilli17600 \cf2 \cb3 \strokec2 \'a0and\'a0
\f2\fs21\fsmilli10800 \cf4 \cb5 \strokec4 .match()
\f1\fs35\fsmilli17600 \cf2 \cb3 \strokec2 \'a0methods allow you to enter any regex pattern and look for a single match at the beginning of a piece of text\cb1 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 The\'a0
\f2\fs21\fsmilli10800 \cf4 \cb5 \strokec4 re
\f1\fs35\fsmilli17600 \cf2 \cb3 \strokec2 \'a0module\'92s\'a0
\f2\fs21\fsmilli10800 \cf4 \cb5 \strokec4 .search()
\f1\fs35\fsmilli17600 \cf2 \cb3 \strokec2 \'a0method lets you find a single match to a regex pattern anywhere in a string, while the\'a0
\f2\fs21\fsmilli10800 \cf4 \cb5 \strokec4 .findall()
\f1\fs35\fsmilli17600 \cf2 \cb3 \strokec2 \'a0method finds all the matches of a regex pattern in a string\cb1 \
\ls1\ilvl0
\f3\i \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Part-of-speech tagging
\f1\i0 \'a0identifies and labels the part of speech of words in a sentence, and can be performed in\'a0
\f2\fs21\fsmilli10800 \cf4 \cb5 \strokec4 nltk
\f1\fs35\fsmilli17600 \cf2 \cb3 \strokec2 \'a0using the\'a0
\f2\fs21\fsmilli10800 \cf4 \cb5 \strokec4 pos_tag()
\f1\fs35\fsmilli17600 \cf2 \cb3 \strokec2 \'a0function\cb1 \
\ls1\ilvl0
\f3\i \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Chunking
\f1\i0 \'a0groups together patterns of words by their part-of-speech tag. Chunking can be performed in\'a0
\f2\fs21\fsmilli10800 \cf4 \cb5 \strokec4 nltk
\f1\fs35\fsmilli17600 \cf2 \cb3 \strokec2 \'a0by defining a piece of chunk grammar using regular expression syntax and calling a\'a0
\f2\fs21\fsmilli10800 \cf4 \cb5 \strokec4 RegexpParser
\f1\fs35\fsmilli17600 \cf2 \cb3 \strokec2 \'91s\'a0
\f2\fs21\fsmilli10800 \cf4 \cb5 \strokec4 .parse()
\f1\fs35\fsmilli17600 \cf2 \cb3 \strokec2 \'a0method on a word tokenized sentence\cb1 \
\ls1\ilvl0
\f3\i \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 NP-chunking
\f1\i0 \'a0chunks together an optional determiner\'a0
\f2\fs21\fsmilli10800 \cf4 \cb5 \strokec4 DT
\f1\fs35\fsmilli17600 \cf2 \cb3 \strokec2 , any number of adjectives\'a0
\f2\fs21\fsmilli10800 \cf4 \cb5 \strokec4 JJ
\f1\fs35\fsmilli17600 \cf2 \cb3 \strokec2 , and a noun\'a0
\f2\fs21\fsmilli10800 \cf4 \cb5 \strokec4 NN
\f1\fs35\fsmilli17600 \cf2 \cb3 \strokec2 \'a0to form a noun phrase. The frequency of different NP-chunks can identify important topics in a text or demonstrate how an author describes different subjects\cb1 \
\ls1\ilvl0
\f3\i \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 VP-chunking
\f1\i0 \'a0chunks together a verb\'a0
\f2\fs21\fsmilli10800 \cf4 \cb5 \strokec4 VB
\f1\fs35\fsmilli17600 \cf2 \cb3 \strokec2 , a noun phrase, and an optional adverb\'a0
\f2\fs21\fsmilli10800 \cf4 \cb5 \strokec4 RB
\f1\fs35\fsmilli17600 \cf2 \cb3 \strokec2 \'a0to form a verb phrase. The frequency of different VP-chunks can give insight into what kind of action different subjects take or how the actions that different subjects take are described by an author, potentially indicating bias\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl560\sa240\partightenfactor0
\ls1\ilvl0
\f3\i \cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 		\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Chunk filtering
\f1\i0 \'a0provides an alternative means of chunking by specifying what parts of speech you do not want in a chunk and removing them\cb1 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs28 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 \
\
\
\'97 
\f4\fs28\fsmilli14080 \cf6 \cb7 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec6 from\cf3 \strokec3  \cf8 \strokec8 nltk\cf3 \strokec3  \cf6 \strokec6 import\cf3 \strokec3  \cf8 \strokec8 RegexpParser\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf6 \cb7 \strokec6 from\cf3 \strokec3  \cf8 \strokec8 pos_tagged_oz\cf3 \strokec3  \cf6 \strokec6 import\cf3 \strokec3  \cf8 \strokec8 pos_tagged_oz\cf3 \cb1 \strokec3 \
\cf6 \cb7 \strokec6 from\cf3 \strokec3  \cf8 \strokec8 np_chunk_counter\cf3 \strokec3  \cf6 \strokec6 import\cf3 \strokec3  \cf8 \strokec8 np_chunk_counter\cf3 \cb1 \strokec3 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # define noun-phrase chunk grammar here\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 chunk_grammar\cf3 \strokec3  = \cf10 \strokec10 "NP: \{<DT>?<JJ>*<NN>\}"\cf3 \cb1 \strokec3 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # create RegexpParser object here\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 chunk_parser\cf3 \strokec3  = \cf8 \strokec8 RegexpParser\cf3 \strokec3 (\cf8 \strokec8 chunk_grammar\cf3 \strokec3 )\cb1 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # create a list to hold noun-phrase chunked sentences\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 np_chunked_oz\cf3 \strokec3  = list()\cb1 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # create a for-loop through each pos-tagged sentence in pos_tagged_oz here\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf6 \cb7 \strokec6 for\cf3 \strokec3  \cf8 \strokec8 pos_tagged_sentence\cf3 \strokec3  \cf6 \strokec6 in\cf3 \strokec3  \cf8 \strokec8 pos_tagged_oz\cf3 \strokec3 :\cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf3 \cb7   \cf9 \strokec9 # chunk each sentence and append to np_chunked_oz here\cf3 \cb1 \strokec3 \
\cb7   \cf8 \strokec8 np_chunked_oz\cf3 \strokec3 .\cf11 \strokec11 append\cf3 \strokec3 (\cf8 \strokec8 chunk_parser\cf3 \strokec3 .\cf11 \strokec11 parse\cf3 \strokec3 (\cf8 \strokec8 pos_tagged_sentence\cf3 \strokec3 ))\cb1 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # store and print the most common np-chunks here\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 most_common_np_chunks\cf3 \strokec3  = \cf8 \strokec8 np_chunk_counter\cf3 \strokec3 (\cf8 \strokec8 np_chunked_oz\cf3 \strokec3 )\cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf3 \cb7 print(\cf8 \strokec8 most_common_np_chunks\cf3 \strokec3 )\cb1 \
\
\
\
\
\'97\cf6 \cb7 \strokec6 import\cf3 \strokec3  \cf8 \strokec8 re\cf3 \cb1 \strokec3 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # characters are defined\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 character_1\cf3 \strokec3  = \cf10 \strokec10 "Dorothy"\cf3 \cb1 \strokec3 \
\cf8 \cb7 \strokec8 character_2\cf3 \strokec3  = \cf10 \strokec10 "Henry"\cf3 \cb1 \strokec3 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # compile your regular expression here\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 regular_expression\cf3 \strokec3 = \cf8 \strokec8 re\cf3 \strokec3 .\cf11 \strokec11 compile\cf3 \strokec3 (\cf10 \strokec10 "[A-Za-z]\{7\}"\cf3 \strokec3 )\cb1 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # check for a match to character_1 here\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 result_1\cf3 \strokec3 =\cf8 \strokec8 regular_expression\cf3 \strokec3 .\cf11 \strokec11 match\cf3 \strokec3 (\cf8 \strokec8 character_1\cf3 \strokec3 )\cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf3 \cb7 print(\cf8 \strokec8 result_1\cf3 \strokec3 )\cb1 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # store and print the matched text here\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 match_1\cf3 \strokec3 =\cf8 \strokec8 result_1\cf3 \strokec3 .\cf11 \strokec11 group\cf3 \strokec3 (\cf8 \strokec8 0\cf3 \strokec3 )\cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf3 \cb7 print(\cf8 \strokec8 match_1\cf3 \strokec3 )\cb1 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # compile a regular expression to match a 7 character string of word characters and check for a match to character_2 here\cf3 \cb1 \strokec3 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 result_2\cf3 \strokec3 =\cf8 \strokec8 re\cf3 \strokec3 .\cf11 \strokec11 match\cf3 \strokec3 (\cf10 \strokec10 "[A-Za-z]\{7\}"\cf3 \strokec3 ,\cf8 \strokec8 character_2\cf3 \strokec3 )\cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf3 \cb7 print(\cf8 \strokec8 result_2\cf3 \strokec3 )\cb1 \
\
\
\
\
\pard\pardeftab720\sl440\partightenfactor0
\cf6 \cb7 \strokec6 import\cf3 \strokec3  \cf8 \strokec8 re\cf3 \cb1 \strokec3 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # import L. Frank Baum's The Wonderful Wizard of Oz\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 oz_text\cf3 \strokec3  = open(\cf10 \strokec10 "the_wizard_of_oz_text.txt"\cf3 \strokec3 ,\cf8 \strokec8 encoding\cf3 \strokec3 =\cf10 \strokec10 'utf-8'\cf3 \strokec3 ).\cf11 \strokec11 read\cf3 \strokec3 ().\cf11 \strokec11 lower\cf3 \strokec3 ()\cb1 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # search oz_text for an occurrence of 'wizard' here\cf3 \cb1 \strokec3 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 found_wizard\cf3 \strokec3 =\cf8 \strokec8 re\cf3 \strokec3 .\cf11 \strokec11 search\cf3 \strokec3 (\cf10 \strokec10 'wizard'\cf3 \strokec3 ,\cf8 \strokec8 oz_text\cf3 \strokec3 )\cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf3 \cb7 print(\cf8 \strokec8 found_wizard\cf3 \strokec3 )\cb1 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # find all the occurrences of 'lion' in oz_text here\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 all_lions\cf3 \strokec3 =\cf8 \strokec8 re\cf3 \strokec3 .\cf11 \strokec11 findall\cf3 \strokec3 (\cf10 \strokec10 'lion'\cf3 \strokec3 ,\cf8 \strokec8 oz_text\cf3 \strokec3 )\cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf3 \cb7 print(\cf8 \strokec8 all_lions\cf3 \strokec3 )\cb1 \
\
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # store and print the length of all_lions here\cf3 \cb1 \strokec3 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 number_lions\cf3 \strokec3 =len(\cf8 \strokec8 all_lions\cf3 \strokec3 )\cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf3 \cb7 print(\cf8 \strokec8 number_lions\cf3 \strokec3 )\cb1 \
\
\
\'97\cf6 \cb7 \strokec6 import\cf3 \strokec3  \cf8 \strokec8 nltk\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf6 \cb7 \strokec6 from\cf3 \strokec3  \cf8 \strokec8 nltk\cf3 \strokec3  \cf6 \strokec6 import\cf3 \strokec3  \cf8 \strokec8 pos_tag\cf3 \cb1 \strokec3 \
\cf6 \cb7 \strokec6 from\cf3 \strokec3  \cf8 \strokec8 word_tokenized_oz\cf3 \strokec3  \cf6 \strokec6 import\cf3 \strokec3  \cf8 \strokec8 word_tokenized_oz\cf3 \cb1 \strokec3 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # save and print the sentence stored at index 100 in word_tokenized_oz here\cf3 \cb1 \strokec3 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 witches_fate\cf3 \strokec3 =\cf8 \strokec8 word_tokenized_oz\cf3 \strokec3 [\cf8 \strokec8 100\cf3 \strokec3 ]\cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf3 \cb7 print(\cf8 \strokec8 witches_fate\cf3 \strokec3 )\cb1 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # create a list to hold part-of-speech tagged sentences here\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 pos_tagged_oz\cf3 \strokec3 =[]\cb1 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # create a for loop through each word tokenized sentence in word_tokenized_oz here\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf6 \cb7 \strokec6 for\cf3 \strokec3  \cf8 \strokec8 token\cf3 \strokec3  \cf6 \strokec6 in\cf3 \strokec3  \cf8 \strokec8 word_tokenized_oz\cf3 \strokec3 :\cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf3 \cb7   \cf9 \strokec9 # part-of-speech tag each sentence and append to pos_tagged_oz here\cf3 \cb1 \strokec3 \
\cb7   \cf8 \strokec8 pos_tagged_oz\cf3 \strokec3 .\cf11 \strokec11 append\cf3 \strokec3 (\cf8 \strokec8 pos_tag\cf3 \strokec3 (\cf8 \strokec8 token\cf3 \strokec3 ))\cb1 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # store and print the 101st part-of-speech tagged sentence here\cf3 \cb1 \strokec3 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 witches_fate_pos\cf3 \strokec3 =\cf8 \strokec8 pos_tagged_oz\cf3 \strokec3 [\cf8 \strokec8 100\cf3 \strokec3 ]\cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf3 \cb7 print(\cf8 \strokec8 witches_fate_pos\cf3 \strokec3 )\cb1 \
\
\
\
\'97\cf6 \cb7 \strokec6 from\cf3 \strokec3  \cf8 \strokec8 nltk\cf3 \strokec3  \cf6 \strokec6 import\cf3 \strokec3  \cf8 \strokec8 RegexpParser\cf3 \strokec3 , \cf8 \strokec8 Tree\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf6 \cb7 \strokec6 from\cf3 \strokec3  \cf8 \strokec8 pos_tagged_oz\cf3 \strokec3  \cf6 \strokec6 import\cf3 \strokec3  \cf8 \strokec8 pos_tagged_oz\cf3 \cb1 \strokec3 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # define adjective-noun chunk grammar here\cf3 \cb1 \strokec3 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 chunk_grammar\cf3 \strokec3  = \cf10 \strokec10 "AN: \{<JJ><NN>\}"\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # create RegexpParser object here\cf3 \cb1 \strokec3 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 chunk_parser\cf3 \strokec3  = \cf8 \strokec8 RegexpParser\cf3 \strokec3 (\cf8 \strokec8 chunk_grammar\cf3 \strokec3 )\cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # chunk the pos-tagged sentence at index 282 in pos_tagged_oz here\cf3 \cb1 \strokec3 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 scaredy_cat\cf3 \strokec3 =\cf8 \strokec8 chunk_parser\cf3 \strokec3 .\cf11 \strokec11 parse\cf3 \strokec3 (\cf8 \strokec8 pos_tagged_oz\cf3 \strokec3 [\cf8 \strokec8 282\cf3 \strokec3 ])\cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf3 \cb7 print(\cf8 \strokec8 scaredy_cat\cf3 \strokec3 )\cb1 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # pretty_print the chunked sentence here\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 Tree\cf3 \strokec3 .\cf11 \strokec11 fromstring\cf3 \strokec3 (str(\cf8 \strokec8 scaredy_cat\cf3 \strokec3 )).\cf11 \strokec11 pretty_print\cf3 \strokec3 ()\
\
\
\
\'97\cf6 \strokec6 from\cf3 \strokec3  \cf8 \strokec8 nltk\cf3 \strokec3  \cf6 \strokec6 import\cf3 \strokec3  \cf8 \strokec8 RegexpParser\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf6 \cb7 \strokec6 from\cf3 \strokec3  \cf8 \strokec8 pos_tagged_oz\cf3 \strokec3  \cf6 \strokec6 import\cf3 \strokec3  \cf8 \strokec8 pos_tagged_oz\cf3 \cb1 \strokec3 \
\cf6 \cb7 \strokec6 from\cf3 \strokec3  \cf8 \strokec8 np_chunk_counter\cf3 \strokec3  \cf6 \strokec6 import\cf3 \strokec3  \cf8 \strokec8 np_chunk_counter\cf3 \cb1 \strokec3 \
\
\cf9 \cb7 \strokec9 # define noun-phrase chunk grammar here\cf3 \cb1 \strokec3 \
\
\cf8 \cb7 \strokec8 chunk_grammar\cf3 \strokec3 =\cf10 \strokec10 "NP: \{<DT>?<JJ>*<NN>\}"\cf3 \cb1 \strokec3 \
\cf9 \cb7 \strokec9 # create RegexpParser object here\cf3 \cb1 \strokec3 \
\
\cf8 \cb7 \strokec8 chunk_parser\cf3 \strokec3 =\cf8 \strokec8 RegexpParser\cf3 \strokec3 (\cf8 \strokec8 chunk_grammar\cf3 \strokec3 )\cb1 \
\cf9 \cb7 \strokec9 # create a list to hold noun-phrase chunked sentences\cf3 \cb1 \strokec3 \
\cf8 \cb7 \strokec8 np_chunked_oz\cf3 \strokec3  = list()\cb1 \
\
\cf9 \cb7 \strokec9 # create a for loop through each pos-tagged sentence in pos_tagged_oz here\cf3 \cb1 \strokec3 \
\cf6 \cb7 \strokec6 for\cf3 \strokec3  \cf8 \strokec8 sentence\cf3 \strokec3  \cf6 \strokec6 in\cf3 \strokec3  \cf8 \strokec8 pos_tagged_oz\cf3 \strokec3 :\cb1 \
\cb7   \cf9 \strokec9 # chunk each sentence and append to np_chunked_oz here\cf3 \cb1 \strokec3 \
\cb7   \cf8 \strokec8 np_chunked_oz\cf3 \strokec3 .\cf11 \strokec11 append\cf3 \strokec3 (\cf8 \strokec8 chunk_parser\cf3 \strokec3 .\cf11 \strokec11 parse\cf3 \strokec3 (\cf8 \strokec8 sentence\cf3 \strokec3 ))\cb1 \
\cb7   \cb1 \
\cf9 \cb7 \strokec9 # store and print the most common np-chunks here\cf3 \cb1 \strokec3 \
\
\cf8 \cb7 \strokec8 most_common_np_chunks\cf3 \strokec3 =\cf8 \strokec8 np_chunk_counter\cf3 \strokec3 (\cf8 \strokec8 np_chunked_oz\cf3 \strokec3  )\cb1 \
\cb7 print(\cf8 \strokec8 most_common_np_chunks\cf3 \strokec3 )\cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf3 \
\
\
\'97\cf6 \cb7 \strokec6 from\cf3 \strokec3  \cf8 \strokec8 nltk\cf3 \strokec3  \cf6 \strokec6 import\cf3 \strokec3  \cf8 \strokec8 RegexpParser\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf6 \cb7 \strokec6 from\cf3 \strokec3  \cf8 \strokec8 pos_tagged_oz\cf3 \strokec3  \cf6 \strokec6 import\cf3 \strokec3  \cf8 \strokec8 pos_tagged_oz\cf3 \cb1 \strokec3 \
\cf6 \cb7 \strokec6 from\cf3 \strokec3  \cf8 \strokec8 vp_chunk_counter\cf3 \strokec3  \cf6 \strokec6 import\cf3 \strokec3  \cf8 \strokec8 vp_chunk_counter\cf3 \cb1 \strokec3 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # define verb phrase chunk grammar here\cf3 \cb1 \strokec3 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 chunk_grammar\cf3 \strokec3  = \cf10 \strokec10 "VP: \{<DT>?<JJ>*<NN><VB.*><RB.?>?\}"\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # create RegexpParser object here\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 chunk_parser\cf3 \strokec3 =\cf8 \strokec8 RegexpParser\cf3 \strokec3 (\cf8 \strokec8 chunk_grammar\cf3 \strokec3 )\cb1 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # create a list to hold verb-phrase chunked sentences\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 vp_chunked_oz\cf3 \strokec3  = list()\cb1 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # create for loop through each pos-tagged sentence in pos_tagged_oz here\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf6 \cb7 \strokec6 for\cf3 \strokec3  \cf8 \strokec8 sentence\cf3 \strokec3  \cf6 \strokec6 in\cf3 \strokec3  \cf8 \strokec8 pos_tagged_oz\cf3 \strokec3 :\cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf3 \cb7   \cf9 \strokec9 # chunk each sentence and append to vp_chunked_oz here\cf3 \cb1 \strokec3 \
\cb7     \cf8 \strokec8 vp_chunked_oz\cf3 \strokec3 .\cf11 \strokec11 append\cf3 \strokec3 (\cf8 \strokec8 chunk_parser\cf3 \strokec3 .\cf11 \strokec11 parse\cf3 \strokec3 (\cf8 \strokec8 sentence\cf3 \strokec3 ))\cb1 \
\cb7   \cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # store and print the most common vp-chunks here\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 most_common_vp_chunks\cf3 \strokec3 =\cf8 \strokec8 vp_chunk_counter\cf3 \strokec3 (\cf8 \strokec8 vp_chunked_oz\cf3 \strokec3  )\cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf3 \cb7 print(\cf8 \strokec8 most_common_vp_chunks\cf3 \strokec3 )\cb1 \
\
\
\
\
\'97\cf6 \cb7 \strokec6 from\cf3 \strokec3  \cf8 \strokec8 nltk\cf3 \strokec3  \cf6 \strokec6 import\cf3 \strokec3  \cf8 \strokec8 RegexpParser\cf3 \strokec3 , \cf8 \strokec8 Tree\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf6 \cb7 \strokec6 from\cf3 \strokec3  \cf8 \strokec8 pos_tagged_oz\cf3 \strokec3  \cf6 \strokec6 import\cf3 \strokec3  \cf8 \strokec8 pos_tagged_oz\cf3 \cb1 \strokec3 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # define chunk grammar to chunk an entire sentence together\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 grammar\cf3 \strokec3  = \cf10 \strokec10 "Chunk: \{<.*>+\}"\cf3 \cb1 \strokec3 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # create RegexpParser object\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 parser\cf3 \strokec3  = \cf8 \strokec8 RegexpParser\cf3 \strokec3 (\cf8 \strokec8 grammar\cf3 \strokec3 )\cb1 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # chunk the pos-tagged sentence at index 230 in pos_tagged_oz\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 chunked_dancers\cf3 \strokec3  = \cf8 \strokec8 parser\cf3 \strokec3 .\cf11 \strokec11 parse\cf3 \strokec3 (\cf8 \strokec8 pos_tagged_oz\cf3 \strokec3 [\cf8 \strokec8 230\cf3 \strokec3 ])\cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf3 \cb7 print(\cf8 \strokec8 chunked_dancers\cf3 \strokec3 )\cb1 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # define noun phrase chunk grammar using chunk filtering here\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 chunk_grammar\cf3 \strokec3 =\cf10 \strokec10 """NP: \{<.*>+\}\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf10 \cb7 \strokec10                        \}<VB.?|IN>+\{"""\cf3 \cb1 \strokec3 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # create RegexpParser object here\cf3 \cb1 \strokec3 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 chunk_parser\cf3 \strokec3  = \cf8 \strokec8 RegexpParser\cf3 \strokec3 (\cf8 \strokec8 chunk_grammar\cf3 \strokec3 )\cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # chunk and filter the pos-tagged sentence at index 230 in pos_tagged_oz here\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 filtered_dancers\cf3 \strokec3  = \cf8 \strokec8 chunk_parser\cf3 \strokec3 .\cf11 \strokec11 parse\cf3 \strokec3 (\cf8 \strokec8 pos_tagged_oz\cf3 \strokec3 [\cf8 \strokec8 230\cf3 \strokec3 ])\cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf3 \cb7 print(\cf8 \strokec8 filtered_dancers\cf3 \strokec3 )\cb1 \
\
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 \cb7 \strokec9 # pretty_print the chunked and filtered sentence here\cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl440\partightenfactor0
\cf8 \cb7 \strokec8 Tree\cf3 \strokec3 .\cf11 \strokec11 fromstring\cf3 \strokec3 (str(\cf8 \strokec8 filtered_dancers\cf3 \strokec3 )).\cf11 \strokec11 pretty_print\cf3 \strokec3 ()\cb1 \
}